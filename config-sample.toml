[from]
chain = "polygon"
datasource = "rpc" # big_query or rpc or file
dapp_type = "uniswap" # uniswap or aave

[from.uniswap]
pool_address = "0x9B08288C3Be4F62bbf8d1C20Ac9C5e6f9467d8B7"

[from.aave]
tokens = [
    "0x7ceb23fd6bc0add59e62ac25578270cff1b9f619",
    "0x2791bca1f2de4661ed88a30c99a7a9449aa84174"
]

[from.big_query] # keep this section according to from.datasource
start = "2022-3-16"
end = "2022-3-17"
auth_file = "./auth/airy-sight-361003-d14b5ce41c48.json" # google bigquery auth file
#http_proxy = "http://localhost:8080"

[from.rpc] # keep this section according to from.datasource
end_point = "https://localhost:8545"
#auth_string = "Basic Y3J0Yzo3NKY3TjY" # auth string for rpc end point
#http_proxy = "http://localhost:8080" # if network is bad, try use proxy
start = "2022-3-16"
end = "2022-3-17"
#batch_size = 500 # default is 500
#keep_tmp_files = false
ignore_position_id = false # if set to true, will not download uniswap proxy logs to get position_id. will save a lot of time
etherscan_api_key = "some_api_key" #

[from.file] # keep this section according to from.datasource
#  either file_path or folder
files = [# full file path you need to convert
    "",
    ""
]
folder = "" # Will convert all raw files in this folder.

[to]
type = "tick" # minute or tick or raw
save_path = "./sample-data"
multi_process = false # process in multi_process, defaut: False

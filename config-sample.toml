[from]
chain = "polygon"
datasource = "rpc" # big_query or rpc or file
pool_address = "0x9B08288C3Be4F62bbf8d1C20Ac9C5e6f9467d8B7"

[from.big_query] # keep this section according to from.datasource
start = "2022-3-16"
end = "2022-3-17"
auth_file = "./auth/airy-sight-361003-d14b5ce41c48.json" # google bigquery auth file
#http_proxy = "http://localhost:8080"

[from.rpc] # keep this section according to from.datasource
end_point = "https://localhost:8545"
#auth_string = "Basic Y3J0Yzo3NKY3TjY"
#http_proxy = "http://localhost:8080" # if network is bad, try use proxy
start = "2022-3-16"
end = "2022-3-17"
#batch_size = 500 # default is 500
#keep_tmp_files = false

[from.file] # keep this section according to from.datasource
files = [
    "",
    ""
]
folder = "" # choose file_path or folder

[to]
type = "minute" # minute or tick or raw
save_path = "./sample-data"
